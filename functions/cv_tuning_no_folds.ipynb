{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from skopt import BayesSearchCV\n",
    "from joblib import parallel_backend\n",
    "\n",
    "from duqling_interface import DuqlingInterface\n",
    "from model_search_spaces import get_models\n",
    "from plot_performance import plot_bayes_cv_rmse, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "duq = DuqlingInterface()\n",
    "\n",
    "univariate_funcs = duq.list_functions(response_type='uni').fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_performance(bayes_search, X_test:np.array, y_test:np.array):\n",
    "    \"\"\"\n",
    "    Compute the test RMSE, standard deviation (sigma), and Pearson's R value\n",
    "    and record them in the cross validation results dictionary.\n",
    "    \"\"\"\n",
    "    y_pred = bayes_search.best_estimator_.predict(X_test)\n",
    "    rmse  = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    sigma = y_test.std(ddof=0)\n",
    "    r     = np.corrcoef(y_pred, y_test)[0, 1]\n",
    "    bayes_search.cv_results_['test_rmse'] = rmse\n",
    "    bayes_search.cv_results_['sigma']     = sigma\n",
    "    bayes_search.cv_results_['r_val']     = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cv_results(cv_results:dict, savepath:Path):\n",
    "    savepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(savepath, 'wb') as f:\n",
    "        pickle.dump(cv_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for duqling_func_name in univariate_funcs[2:3]:\n",
    "\n",
    "    X_tr, y_tr = duq.generate_data(duqling_func_name, n_samples=1000, seed=42)\n",
    "    X_va, y_va = duq.generate_data(duqling_func_name, n_samples=1000, seed=43)\n",
    "    X_te, y_te = duq.generate_data(duqling_func_name, n_samples=1000, seed=44)\n",
    "\n",
    "    X_tune = np.vstack([X_tr, X_va])\n",
    "    y_tune = np.hstack([y_tr, y_va])\n",
    "\n",
    "    test_fold = np.r_[np.full(len(X_tr), -1), np.zeros(len(X_va))]\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "\n",
    "    n_features = X_tr.shape[1]\n",
    "    models = get_models(n_features)\n",
    "    models.pop('gpr')\n",
    "    for model_name in models:\n",
    "        total_iters = models[model_name]['n_iter']\n",
    "        bar = tqdm(total=total_iters, desc=f\"{model_name.upper()} on {duqling_func_name}\", unit=\"iter\")\n",
    "        def update_tqdm_bar(_): bar.update()\n",
    "\n",
    "        bayes_search = BayesSearchCV(\n",
    "            **models[model_name],\n",
    "            cv=ps,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        with parallel_backend('threading', n_jobs=-1):\n",
    "            bayes_search.fit(X_tune, y_tune, callback=update_tqdm_bar)\n",
    "        bar.close()\n",
    "        \n",
    "        record_performance(bayes_search, X_te, y_te)\n",
    "\n",
    "        # plot_bayes_cv_rmse(bayes_search.cv_results_, model_name.upper(), duqling_func_name)\n",
    "\n",
    "        savepath = Path(\"models\", model_name, duqling_func_name, f\"cv_no_fold_results.pkl\")\n",
    "        save_cv_results(bayes_search.cv_results_, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "metrics     = [\"test_rmse\", \"sigma\", \"r_val\"]\n",
    "model_names = [m for m in get_models(1).keys() if m != 'gpr']\n",
    "\n",
    "arr = np.full((len(metrics), len(model_names), len(univariate_funcs)), np.nan)\n",
    "\n",
    "for j, model in enumerate(model_names):\n",
    "    for k, func in enumerate(univariate_funcs):\n",
    "        pkl = Path('models', model, func, 'cv_no_fold_results.pkl')\n",
    "        if not pkl.exists():\n",
    "            continue\n",
    "        with pkl.open(\"rb\") as fh:\n",
    "            data = pickle.load(fh)\n",
    "        for i, m in enumerate(metrics):\n",
    "            arr[i, j, k] = data[m]\n",
    "\n",
    "summary = xr.DataArray(\n",
    "    arr,\n",
    "    coords={\"metric\": metrics, \"model\": model_names, \"function\": univariate_funcs},\n",
    "    dims=[\"metric\", \"model\", \"function\"]\n",
    ")\n",
    "\n",
    "def metric_df(metric: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a model and function DataFrame for a single metric.\"\"\"\n",
    "    return summary.sel(metric=metric).to_pandas()\n",
    "\n",
    "df_rmse = metric_df('test_rmse')\n",
    "df_r    = metric_df('r_val')\n",
    "df_std  = metric_df('sigma')\n",
    "\n",
    "cols_to_drop = [\n",
    "    # 'circuit', 'cantilever_S', 'banana', 'cube3_rotate', 'steel_column',\n",
    "    'const_fn', 'const_fn3', 'const_fn15', 'cube3_rotate'\n",
    "]\n",
    "fig1 = heatmap(df_rmse.drop(cols_to_drop, axis=1), \"Test RMSE\")\n",
    "fig2 = heatmap((df_rmse/df_std).drop(cols_to_drop, axis=1), \"Test RMSE / \\u03C3\")\n",
    "fig3 = heatmap((df_rmse/df_std)[(df_rmse/df_std).drop(cols_to_drop, axis=1)>1].drop(cols_to_drop, axis=1), \"(Test RMSE / \\u03C3) > 1\")\n",
    "\n",
    "df_filtered = (df_rmse/df_std)[(df_rmse/df_std).drop(cols_to_drop, axis=1)>1].drop(cols_to_drop, axis=1)\n",
    "drop_cols = df_filtered.columns[df_filtered.isnull().all()]\n",
    "fig4 = heatmap(df_filtered.drop(drop_cols, axis=1), \"(Test RMSE / \\u03C3) > 1\")\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(df_rmse[df_filtered.drop(drop_cols, axis=1).columns], 'Test RMSE at Outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bed4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duqling_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
